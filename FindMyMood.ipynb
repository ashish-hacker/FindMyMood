{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re , string , random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   40000 non-null  int64 \n",
      " 1   sentiment  40000 non-null  object\n",
      " 2   author     40000 non-null  object\n",
      " 3   content    40000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_array = [i.split(' ') for i in np.array(data.content[data.sentiment == 'neutral'])]\n",
    "worry_array =[i.split(' ') for i in  np.array(data.content[data.sentiment == 'worry'])]\n",
    "happy_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'happiness'])]\n",
    "sad_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'sadness'])]\n",
    "love_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'love'])]\n",
    "surprise_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'surprise'])]\n",
    "fun_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'fun'])]\n",
    "relief_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'relief'])]\n",
    "hate_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'hate'])]\n",
    "empty_array = [i.split(' ') for i in np.array(data.content[data.sentiment == 'empty'])]\n",
    "enthu_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'enthusiasm'])]\n",
    "bore_array = [ i.split(' ') for i in np.array(data.content[data.sentiment == 'boredom'])]\n",
    "anger_array =[ i.split(' ') for i in np.array(data.content[data.sentiment == 'anger'])]\n",
    "\n",
    "n_arrays = [neutral_array, worry_array, happy_array, sad_array, love_array, surprise_array, fun_array, relief_array, hate_array, empty_array, enthu_array, anger_array, bore_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_dat  = []\n",
    "worry_dat  = []\n",
    "happ_dat = []\n",
    "sad_dat = []\n",
    "love_dat = []   \n",
    "surprise_dat = [] \n",
    "fun_dat = [] \n",
    "relief_dat = [] \n",
    "hate_dat = []\n",
    "empty_dat = []\n",
    "enth_dat = []\n",
    "bore_dat= []\n",
    "anger_dat = []\n",
    "\n",
    "arrays = [neutral_dat, worry_dat, happ_dat, sad_dat, love_dat, surprise_dat, fun_dat, relief_dat, hate_dat, empty_dat, enth_dat, anger_dat, bore_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in zip(n_arrays, arrays):\n",
    "    for j in i:\n",
    "        j = [x for x in j if x!='']\n",
    "        k.append(remove_noise(j,stop_words))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " 'great',\n",
       " 'to',\n",
       " 'see',\n",
       " 'Oin',\n",
       " '&amp;',\n",
       " 'Cynthia.',\n",
       " '',\n",
       " 'So',\n",
       " 'happy.',\n",
       " '',\n",
       " 'Dinner',\n",
       " 'was',\n",
       " 'great,',\n",
       " 'cute',\n",
       " 'little',\n",
       " 'place.',\n",
       " '',\n",
       " 'Too',\n",
       " 'bad',\n",
       " 'Oin',\n",
       " 'got',\n",
       " 'sick',\n",
       " 'afterwards.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'see',\n",
       " 'oin',\n",
       " '&amp;',\n",
       " 'cynthia.',\n",
       " 'happy.',\n",
       " 'dinner',\n",
       " 'great,',\n",
       " 'cute',\n",
       " 'little',\n",
       " 'place.',\n",
       " 'bad',\n",
       " 'oin',\n",
       " 'get',\n",
       " 'sick',\n",
       " 'afterwards.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happ_dat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_words = get_all_words(neutral_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('get', 705), ('go', 660), (\"i'm\", 468), ('good', 385), ('work', 351), ('like', 339), ('day', 331), ('one', 285), ('think', 264), ('back', 263)]\n"
     ]
    }
   ],
   "source": [
    "freq_dist_pos = FreqDist(all_pos_words)\n",
    "print(freq_dist_pos.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_model = get_words_for_model(happ_dat)\n",
    "neutral_model = get_words_for_model(neutral_dat)\n",
    "worry_model = get_words_for_model(worry_dat)\n",
    "sad_model = get_words_for_model(sad_dat)\n",
    "love_model = get_words_for_model(love_dat)\n",
    "surprise_model = get_words_for_model(surprise_dat)\n",
    "fun_model = get_words_for_model(fun_dat)\n",
    "relief_model = get_words_for_model(relief_dat)\n",
    "hate_model = get_words_for_model(hate_dat)\n",
    "empty_model = get_words_for_model(empty_dat)\n",
    "enth_model = get_words_for_model(enth_dat)\n",
    "bore_model = get_words_for_model(bore_dat)\n",
    "anger_model = get_words_for_model(anger_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_dataset = [(tweet_dict, \"happy\")\n",
    "                         for tweet_dict in happy_model]\n",
    "neutral_dataset = [(tweet_dict, \"neutral\")\n",
    "                         for tweet_dict in neutral_model]\n",
    "worry_dataset = [(tweet_dict, \"worry\")\n",
    "                         for tweet_dict in worry_model]\n",
    "sad_dataset = [(tweet_dict, \"sad\")\n",
    "                         for tweet_dict in sad_model]\n",
    "love_dataset = [(tweet_dict, \"love\")\n",
    "                         for tweet_dict in love_model]\n",
    "hate_dataset = [(tweet_dict, \"hate\")\n",
    "                         for tweet_dict in hate_model]\n",
    "surprise_dataset = [(tweet_dict, \"surprise\")\n",
    "                         for tweet_dict in surprise_model]\n",
    "fun_dataset = [(tweet_dict, \"fun\")\n",
    "                         for tweet_dict in fun_model]\n",
    "relief_dataset = [(tweet_dict, \"relief\")\n",
    "                         for tweet_dict in relief_model]\n",
    "empty_dataset = [(tweet_dict, \"empty\")\n",
    "                         for tweet_dict in empty_model]\n",
    "enth_dataset = [(tweet_dict, \"enthusiastic\")\n",
    "                         for tweet_dict in enth_model]\n",
    "bore_dataset = [(tweet_dict, \"boredom\")\n",
    "                         for tweet_dict in bore_model]\n",
    "anger_dataset = [(tweet_dict, \"angry\")\n",
    "                         for tweet_dict in anger_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = anger_dataset + bore_dataset + enth_dataset + empty_dataset + relief_dataset + fun_dataset + surprise_dataset + hate_dataset + love_dataset + sad_dataset + worry_dataset + neutral_dataset + happy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[:35000]\n",
    "test_data = dataset[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is:\", classify.accuracy(classifier, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    bore = True           boredo : happy  =    180.7 : 1.0\n",
      "                    hate = True             hate : happy  =    153.9 : 1.0\n",
      "                   annoy = True            angry : neutra =    133.2 : 1.0\n",
      "                   stuck = True           boredo : neutra =     87.6 : 1.0\n",
      "                    mrs. = True           boredo : neutra =     81.1 : 1.0\n",
      "                sooooooo = True           boredo : neutra =     81.1 : 1.0\n",
      "                     wtf = True           boredo : neutra =     81.1 : 1.0\n",
      "                 fifteen = True           boredo : neutra =     81.1 : 1.0\n",
      "                   hell. = True           boredo : neutra =     81.1 : 1.0\n",
      "                 sunday. = True            angry : neutra =     79.9 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sentence = \"I failed \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokens = remove_noise(word_tokenize(custom_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I failed  \n",
      "Emotion: sad\n"
     ]
    }
   ],
   "source": [
    "print('Sentence:',custom_sentence,'\\nEmotion:', classifier.classify(dict([token, True] for token in custom_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
